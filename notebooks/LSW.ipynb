{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00f19f3e-f05e-43ea-9a8d-30b9b75be4aa",
   "metadata": {},
   "source": [
    "# This Notebook implements Latent Space Walk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c58001-debc-46a1-ab90-00da2d014973",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d99f179-2f0c-4225-8dae-fe446f8158e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getcwd().split('/')[-1] == 'notebooks':\n",
    "    os.chdir('../')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as dset\n",
    "from torchvision import transforms\n",
    "from torch import autograd\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ignite\n",
    "import ignite.distributed as idist\n",
    "from ignite.metrics import FID, InceptionScore\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a2d99a-1227-47a5-8afa-7b8ac6632b84",
   "metadata": {},
   "source": [
    "# 2. Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466dfe0a-3d3d-4d30-a85c-447c71ac808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0355d94-0fdc-431c-9cae-577bc49d8be3",
   "metadata": {},
   "source": [
    "# 3. Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec6290-aa4a-4401-8fd7-2347f2124d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = torch.load('./models/netG_dcgan_bce.pkl').to(device)\n",
    "netD = torch.load('./models/netD_dcgan_bce.pkl').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beea212-5b76-4223-ab8e-c1148886e006",
   "metadata": {},
   "source": [
    "# 3. Prepare Latent Space Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c48c42-d7a0-4224-93f2-165ed3e5b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(image_tensor, num_images=16, size=(3, 64, 64), nrow=3):\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273647d1-c7da-4776-b4b0-dcae5d0498c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 8\n",
    "nz = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb828458-dd95-4bb5-837c-2a5df709e0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_noises(p1, p2, n_steps=6):\n",
    "    # interpolate ratios between the points\n",
    "    ratios = np.linspace(0, 1, num=n_steps)\n",
    "    # linear interpolate vectors\n",
    "    vectors = list()\n",
    "    vectors.append(p1)\n",
    "    for ratio in ratios:\n",
    "        v = (1.0 - ratio) * p1 + ratio * p2\n",
    "        vectors.append(v)\n",
    "    vectors.append(p2)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8acdcf-06f8-4540-afb8-b31d8f312249",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_images = []\n",
    "# generate with interpolation\n",
    "noise1 = torch.randn(num_images, nz, 1, 1, device=device)\n",
    "noise2 = torch.randn(num_images, nz, 1, 1, device=device)\n",
    "vectors = interpolate_noises(noise1, noise2)\n",
    "for noise in vectors:\n",
    "    fake = netG(noise)\n",
    "    fake_images += [fake]\n",
    "plt.rcParams['figure.figsize'] = [num_images * 2, len(vectors) * 2]\n",
    "plt.axis('off')\n",
    "show_images(torch.cat(fake_images, dim=2), num_images=num_images, nrow=num_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006c1c26-d94b-4c72-928d-c16884905f92",
   "metadata": {},
   "source": [
    "### Models comparison on fixed noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38ab64a-f76a-473e-af0e-0c3a14c54c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz, nc, ngf, drop_rate):\n",
    "        super(Generator, self).__init__()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=nz, out_channels=ngf * 8, kernel_size=2, stride=1, \n",
    "                               padding=0, bias=False),\n",
    "            nn.Dropout2d(p=drop_rate),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose2d(in_channels=ngf * 8, out_channels=ngf * 4, kernel_size=4, stride=2, \n",
    "                               padding=0, bias=False),\n",
    "            nn.Dropout2d(p=drop_rate),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose2d(in_channels=ngf * 4, out_channels=ngf * 2, kernel_size=5, stride=3, \n",
    "                               padding=1, bias=False),\n",
    "            nn.Dropout2d(p=drop_rate),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose2d(in_channels=ngf * 2, out_channels=ngf, kernel_size=6, stride=4, \n",
    "                               padding=0, bias=False),\n",
    "            nn.Dropout2d(p=drop_rate),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose2d(in_channels=ngf, out_channels=nc, kernel_size=12, stride=4, \n",
    "                               padding=2, bias=False)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        input_ = self.main(input_)\n",
    "        return self.softmax(input_)\n",
    "    \n",
    "# custom weights initialization called on ``netG`` and ``netD``\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80901d1-6aa0-415e-af92-91a323786a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator\n",
    "netG = Generator(nz, 3, 32, 0.05).to(device)\n",
    "# netG = torch.load('./models/netG.pkl').to('cpu')\n",
    "\n",
    "# # Handle multi-GPU if desired\n",
    "# if (device.type == 'cuda') and (ngpu > 1):\n",
    "#     netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# Apply the ``weights_init`` function to randomly initialize all weights\n",
    "#  to ``mean=0``, ``stdev=0.02``.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005307cb-ee43-4616-b32c-59d4a34a4232",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 5\n",
    "nz = 512\n",
    "noise = torch.randn(num_images, nz, 1, 1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac2adda-e600-480c-976e-537790dc547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_images[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f890d1-2fb6-463b-92ac-5d968a55652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349170bf-f3c7-4bc4-9950-cf7aece54f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_true = torch.load('./data/test.pkl')\n",
    "dataloader = torch.utils.data.DataLoader(x_true, batch_size=5, \n",
    "                                             shuffle=True, num_workers=4, drop_last=True)\n",
    "x_true = next(iter(dataloader))\n",
    "x_true = x_true[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e93baa-77ed-41f7-a150-476852ee8ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c84dbb-3970-4f60-9eb5-682a98133ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_images += [x_true]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960585fb-471a-4b29-a56b-261b4426fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = torch.load('./models/netD_dcgan_bce.pkl').to(device)\n",
    "noise = torch.randn(num_images, 100, 1, 1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4685ea-64ae-4de0-9434-2254a1013f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = netG(noise)\n",
    "fake_images += [fake]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757e87b4-c991-4d3d-8432-a8e3faddfb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [num_images * 2, len(fake_images) * 2]\n",
    "plt.axis('off')\n",
    "show_images(torch.cat(fake_images, dim=2), num_images=num_images, nrow=num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baccdf64-883c-4aec-9963-b19cb34e117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = fake[2].cpu().detach()\n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(img.permute(1,2,0), cmap='gray');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
