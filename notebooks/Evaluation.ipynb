{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4240a39-6c6e-4841-a899-b71736e4ea90",
   "metadata": {},
   "source": [
    "# Evaluation of the GAN Greyscale 64 px model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ef34c0-5b7d-4596-90ee-018f11256298",
   "metadata": {},
   "source": [
    "# 1. Import Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0125a70-c3fe-4236-bcbf-e3badb8b6f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import numpy as np\n",
    "if os.getcwd().split('/')[-1] == 'notebooks':\n",
    "    os.chdir('../')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as dset\n",
    "from torchvision import transforms\n",
    "from torch import autograd\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils # draw bounding box, segmantation mask, keypoints. convert to rgb, make grid, save_image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import ignite\n",
    "# import ignite.distributed as idist\n",
    "# from ignite.metrics import FID, InceptionScore, RunningAverage\n",
    "# from ignite.contrib.handlers import ProgressBar\n",
    "# from ignite.engine import Engine, Events\n",
    "# from ignite.handlers import *\n",
    "import PIL.Image as Image\n",
    "\n",
    "from src.utils import geometric_score as gs\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60afa015-cf10-4b98-8ab7-05ee5016d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAROOT = \"./data/cadastralExportRGB/train/\"  # root directory for dataset\n",
    "WORKERS = 4  # number of workers for dataloader\n",
    "BATCH_SIZE = 2000  # batch size during training\n",
    "IMG_SIZE = 300  # spatial size of training images (to be resized to)\n",
    "MULT = 3.15  # re-size factor: 11 if resolution is 64 x 64, 3.15 if resolution is 300 x 300\n",
    "NC = 3  # number of entities aka channels in the training images\n",
    "NZ = 512  # size of noise vector (i.e. size of generator input)\n",
    "NGF = 32  # base size of feature maps in generator\n",
    "NDF = 32  # base size of feature maps in discriminator\n",
    "NUM_EPOCHS = 1000  # number of training epochs\n",
    "LR = 1e-2  # learning rate for both optimizers\n",
    "DEVICE = 'cpu'\n",
    "# DEVICE = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")  # which device to run on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f38c1e68-6f3c-4613-94ca-64a2b16e975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_true = torch.load('./data/test.pkl')\n",
    "dataloader = torch.utils.data.DataLoader(x_true, batch_size=BATCH_SIZE, \n",
    "                                             shuffle=True, num_workers=4, drop_last=True)\n",
    "x_true = next(iter(dataloader))\n",
    "x_true = x_true[0].to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa656094-9a3b-4c8a-8b68-396859d6d397",
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = torch.load('./models/netG_dcgan_embeddings.pkl').to(DEVICE)\n",
    "fixed_noise = torch.randn(2000, NZ, 1, 1, device=DEVICE)\n",
    "x_pred = netG(fixed_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654fe254-97cc-403b-aa64-098b53937141",
   "metadata": {},
   "source": [
    "# Calculating Geometric Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246579a2-9d49-4316-8ea8-363a7b3ad2a4",
   "metadata": {},
   "source": [
    "Implementation: https://github.com/KhrulkovV/geometry-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad507b6c-2973-4501-b18f-a3ae65cc4afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0/100\n",
      "Done 10/100\n",
      "Done 20/100\n",
      "Done 30/100\n",
      "Done 40/100\n",
      "Done 50/100\n",
      "Done 60/100\n",
      "Done 70/100\n",
      "Done 80/100\n",
      "Done 90/100\n"
     ]
    }
   ],
   "source": [
    "rltx = gs.rlts(x_true[:, 1, :, :].view(BATCH_SIZE, -1).numpy(), n=100, L_0=32, i_max=10, gamma=1.0/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd334d5-9a8c-4c85-a8d9-4059113aa2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0/100\n"
     ]
    }
   ],
   "source": [
    "rlty = gs.rlts(x_pred[:, 1, :, :].view(BATCH_SIZE, -1).cpu().detach().numpy(), n=100, L_0=32, i_max=10, gamma=1.0/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70228a5-fd95-4086-acc0-793d791d0175",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.geom_score(rltx, rlty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ef64ec8-353b-4c69-afe2-7c2f497467c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010152160286518088"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.geom_score(rltx, rlty)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
